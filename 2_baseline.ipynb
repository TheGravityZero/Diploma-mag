{"cells":[{"cell_type":"markdown","metadata":{"id":"n0LRsSgjt2rc"},"source":["# Пайплайн Baseline подхода с GigaChat"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WihE00uBt2ri"},"outputs":[],"source":["import os\n","from dotenv import load_dotenv, find_dotenv\n","from langchain_gigachat import Gigachat\n","\n","load_dotenv(find_dotenv())\n","\n","def init_gigachat():\n","    return Gigachat(credentials=\"ваш_ключ_авторизации\", model=\"GigaChat-Max\", verify_ssl_certs=False, temperature=1e-15, timeout=100)\n","\n","llm = init_gigachat()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YdCi7I9vt2rl"},"outputs":[],"source":["question = \"Как установить PhotoShop?\"\n","response = llm.invoke(question)"]},{"cell_type":"markdown","metadata":{"id":"oAqS2sKqt2rm"},"source":["# Пайплайн подхода LLaVA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TOcVwP6ct2rn"},"outputs":[],"source":["from transformers import BitsAndBytesConfig, LlavaNextProcessor, LlavaNextForConditionalGeneration\n","from PIL import Image\n","import io\n","import pandas as pd\n","from typing import Tuple\n","from rag_env import INPUT_DATA\n","\n","\n","quantization_config = BitsAndBytesConfig(\n","    load_in_8bit=True,\n","    low_cpu_mem_usage=True,\n","    use_flash_attention_2=True\n",")\n","\n","def format_output(raw_output, processor: LlavaNextProcessor, prompt: str) -> str:\n","    out = processor.decode(raw_output[0], skip_special_tokens=True)\n","    out_prompt = prompt.replace(\"<image>\", \" \").strip()\n","    formatted_output = out.replace(out_prompt, \"\").strip()\n","    return formatted_output\n","\n","\n","def llava_call(prompt: str, model: LlavaNextForConditionalGeneration, processor: LlavaNextProcessor, device: str, image: Image=None) -> str:\n","\n","    inputs = processor(prompt, image, return_tensors=\"pt\").to(device)\n","    raw_output = model.generate(**inputs, max_new_tokens=300)\n","    formatted_output = format_output(raw_output, processor, prompt)\n","    return formatted_output\n","\n","\n","def load_llava_model(model_id: str) -> Tuple[LlavaNextForConditionalGeneration, LlavaNextProcessor]:\n","    processor = LlavaNextProcessor.from_pretrained(model_id)\n","    # uncomment to use quantized version of the model\n","    # model = LlavaNextForConditionalGeneration.from_pretrained(model_id, quantization_config=quantization_config, device_map=\"auto\")\n","    model = LlavaNextForConditionalGeneration.from_pretrained(model_id, device_map=\"auto\")\n","    return model, processor\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pe4OojQSt2ro"},"outputs":[],"source":["device = \"cuda\"\n","model, processor = load_llava_model(\"llava-hf/llava-v1.6-mistral-7b-hf\")\n","model = model.eval()\n","\n","\n","prompt = f\"[INST]\\nQuestion:\\n{question}\\n\\n[/INST]\"\n","question = \"What are the possible positions of the manual operator and what colors are associated with each position?\"\n","\n","llava_response_no_img = llava_call(no_img_prompt, model, processor, device)\n","print(llava_response_no_img)"]},{"cell_type":"markdown","metadata":{"id":"ANyz3Z8nt2rp"},"source":["# Оценка ответа"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q-F35Io4t2rp"},"outputs":[],"source":["def init_deepseek():\n","    return Gigachat(model=\"DeepSeek-R1\", verify_ssl_certs=False, temperature=1e-15, timeout=100)\n","\n","llm = init_deepseek()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3pIfBP4Rt2rq"},"outputs":[],"source":["from langchain.prompts import ChatPromptTemplate\n","from prompts import ANSWER_CORRECTNESS_SYSTEM, ANSWER_CORRECTNESS_USER\n","\n","answer_correctness = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", ANSWER_CORRECTNESS_SYSTEM),\n","        (\"human\", ANSWER_CORRECTNESS_USER)\n","    ]\n",")\n","llm = init_deepseek()\n","\n","answer_correctness_chain = answer_correctness | llm\n","response = answer_correctness_chain.invoke(\"question\": question, \"reference_answer\": reference_answer, \"generated_answer\": generated_answer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o_U-E88_t2rr"},"outputs":[],"source":["from langchain.prompts import ChatPromptTemplate\n","from prompts import ANSWER_RELEVANCE_SYSTEM, ANSWER_RELEVANCE_USER\n","\n","answer_correctness = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", ANSWER_CORRECTNESS_SYSTEM),\n","        (\"human\", ANSWER_CORRECTNESS_USER)\n","    ]\n",")\n","llm = init_deepseek()\n","\n","answer_correctness_chain = answer_correctness | llm\n","response = answer_correctness_chain.invoke(\"query\": question, \"text\": generated_answer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5XZBWEYMt2rs"},"outputs":[],"source":["from langchain.prompts import ChatPromptTemplate\n","from prompts import CONTEXT_RELEVANCE_TEXT_SYSTEM, CONTEXT_RELEVANCE_TEXT_USER\n","\n","answer_correctness = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", ANSWER_CORRECTNESS_SYSTEM),\n","        (\"human\", ANSWER_CORRECTNESS_USER)\n","    ]\n",")\n","llm = init_deepseek()\n","\n","answer_correctness_chain = answer_correctness | llm\n","response = answer_correctness_chain.invoke(\"query\": question, \"context\": generated_answer)"]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.11"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}