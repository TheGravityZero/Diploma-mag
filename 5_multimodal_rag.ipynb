{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35608,
     "status": "ok",
     "timestamp": 1748385718955,
     "user": {
      "displayName": "Руслан",
      "userId": "08306979938033836096"
     },
     "user_tz": -180
    },
    "id": "x45VDmDa5c65",
    "outputId": "ec6a24f4-b98b-4443-f43a-63086780c15a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#root_path = \"/content/drive/MyDrive/Diploma-mag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -q -U langchain langchain-gigachat open-clip-torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LDE3M3e84J7-"
   },
   "outputs": [],
   "source": [
    "from langchain_gigachat import Gigachat\n",
    "from langchain_gigachat.embeddings import GigaChatEmbeddings\n",
    "\n",
    "def init_gigachat():\n",
    "    return Gigachat(credentials=\"ключ_авторизации\", model=\"GigaChat-Max\", verify_ssl_certs=False, temperature=1e-15, timeout=100)\n",
    "\n",
    "\n",
    "def init_gigachat_embeddings():\n",
    "    return GigaChatEmbeddings(credentials=\"ключ_авторизации\", scope-\"GIGACHAT_API_PER\", verify_ssl_certs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JAhPjuoaPNZU"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import open_clip\n",
    "\n",
    "from PIL import Image\n",
    "from typing import List, Union\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class OpenCLIPEmbeddings(Embeddings):\n",
    "    def __init__(self, model_name: str = \"ViT-H-14\", pretrained: str = \"/Users/User/Downloads/CLIP-ViT-H-14-laion2B-s32B-b79K/open_clip_model.safetensors\"):\n",
    "        self.model,  self.preprocess = open_clip.create_model_from_pretrained(model_name, pretrained=pretrained)\n",
    "        self.tokenizer = open_clip.get_tokenizer(model_name)\n",
    "        self.model.eval()\n",
    "\n",
    "    def _normalize(self, tensor: torch.Tensor) -> List[float]:\n",
    "        return tensor.div(tensor.norm(p=2, dim=-1, keepdim=True)).squeeze(0).tolist()\n",
    "\n",
    "    def embed_text(self, text: str) -> List[float]:\n",
    "        tokens = self.tokenizer(text)\n",
    "        with torch.no_grad():\n",
    "            embeddings = self.model.encode_text(tokens)\n",
    "        return self._normalize(embeddings)\n",
    "\n",
    "    def embed_image(self, uris: List[str]) -> List[List[float]]:\n",
    "        pil_images = [Image.open(uri) for uri in uris]\n",
    "        image_features = []\n",
    "        for pil_image in tqdm(pil_images):\n",
    "            preprocessed_image = self.preprocess(pil_image).unsqueeze(0)\n",
    "            embeddings_tensor = self.model.encode_image(preprocessed_image)\n",
    "            norm = embeddings_tensor.norm(p=2, dim=1, keepdim=True)\n",
    "            normalized_embeddings_tensor = embeddings_tensor.div(norm)\n",
    "            embeddings_list = normalized_embeddings_tensor.squeeze(0).tolist()\n",
    "            image_features.append(embeddings_list)\n",
    "        return image_features\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return [self.embed_image(text) for text in texts]\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self.embed_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NqG3jP6h4J8E"
   },
   "outputs": [],
   "source": [
    "llm = init_gigachat()\n",
    "embeddings = init_gigachat_embeddings()\n",
    "image_embeddigns = OpenCLIPEmbeddings()\n",
    "\n",
    "model_id = \"gigachat\"\n",
    "text_embedding_model = \"gigaEmbeddings\"\n",
    "image_embeddign_model = \"clip\"\n",
    "\n",
    "img_vectorstore_dir = f\"./data/multimodal_rag/image_{model_id}_vectorstore_{image_embeddign_model}\"\n",
    "text_vectorstore_dir = f\"./data/multimodal_rag/text_{model_id}_vectorstore_{text_embedding_model}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4TppRLi6PT_I"
   },
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from chromadb.config import Settings\n",
    "\n",
    "text_vectorstore = Chroma(\n",
    "    persist_directory=text_vectorstore_dir,\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"mm_rag_text_gigaembeddings\",\n",
    "    client_settings=Settings(anonymized_telemetry=False)\n",
    ")\n",
    "\n",
    "img_vectorstore = Chroma(\n",
    "        persist_directory=img_vectorstore_dir,\n",
    "        embedding_function=image_embeddigns,\n",
    "        collection_name=f\"mm_rag_image_gigaembeddings\",\n",
    "        client_settings=Settings(anonymized_telemetry=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EttfQgq2eQMr"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"./extracted_data/extracted_texts.json\", \"r\") as f:\n",
    "    documents = json.load(f)\n",
    "\n",
    "with open(\"./extracted_data/extracted_images.json\", \"r\") as f:\n",
    "    images = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kg_WOX-FPYbo"
   },
   "outputs": [],
   "source": [
    "uris = [f\"./extracted_data/source_images/image_{j}.png\" for j in range(len(images))]\n",
    "metadatas = [{\"page_number\": images[j][\"page_number\"], \"image_path\": uris[j]} for j in range(len(images))]\n",
    "\n",
    "img_vectorstore.add_images(\n",
    "    uris=uris,\n",
    "    metadatas=metadatas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eoiR7G2vPUcY"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"./extracted_data/extracted_texts.json\", \"r\") as f:\n",
    "    documents = json.load(f)\n",
    "\n",
    "with open(\"./extracted_data/extracted_images.json\", \"r\") as f:\n",
    "    images = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5NqwG76PcvY"
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "\n",
    "documents_content = []\n",
    "documents_page = []\n",
    "\n",
    "for d in documents:\n",
    "    documents_content.append(d[\"text\"])\n",
    "    documents_page.append(d[\"metadata\"][\"page_number\"])\n",
    "\n",
    "prepared_text = []\n",
    "for i, document_content in enumerate(documents_content):\n",
    "    chunks = text_splitter.split_text(document_content)\n",
    "    doc_ids += [str(uuid.uuid4()) for _ in chunks]\n",
    "    prepared_text += [Document(\n",
    "        page_content=chunk,\n",
    "        metadata={\n",
    "            \"page_number\": documents_page[i]\n",
    "        })\n",
    "    for j, chunk in enumerate(chunks)]\n",
    "\n",
    "all_chunks = [text.page_content for text in prepared_text]\n",
    "\n",
    "text_vectorstore.add_documents(prepared_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ADJYK0FsPjCc"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from prompts import QA_PROMPT_SYSTEM, QA_PROMPT_USER\n",
    "\n",
    "def run_pipeline_gigachat(question, text_vectorstore, img_vectorstore, llm):\n",
    "    text_content = text_vectorstore.similarity_search(question, k=4)\n",
    "    image_content = img_vectorstore.similarity_search(question, k=1)\n",
    "\n",
    "    context = \"\\n\\n\".join([t.page_content for t in text_content])\n",
    "    img_path = image_content[0].metadata[\"image_path\"]\n",
    "    file = llm.upload_file(open(img_path, \"rb\"))\n",
    "\n",
    "    text_content = QA_PROMPT_USER.format(context=context, question=question)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", QA_PROMPT_SYSTEM),\n",
    "            HumanMessage(content=text_content, additional_kwargs={\"attachments\": [file.id_]})\n",
    "        ]\n",
    "    )\n",
    "    chain = prompt | llm\n",
    "\n",
    "    return  chain.invoke({}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oDTfoCwIPlFO"
   },
   "outputs": [],
   "source": [
    "question = \"Как выделить прямоугольную область на изображении в Adobe Photoshop?\"\n",
    "run_pipeline_gigachat(question, text_vectorstore, img_vectorstore, llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6khfAQR4RoT"
   },
   "source": [
    "# LLaVa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N3FgMdw-4Sv9"
   },
   "outputs": [],
   "source": [
    "#!pip install -q -U transformers bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUFxZPIhZ2N-"
   },
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig, LlavaNextProcessor, LlavaNextForConditionalGeneration\n",
    "from PIL import Image\n",
    "import io\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    low_cpu_mem_usage=True,\n",
    "    use_flash_attention_2=True\n",
    ")\n",
    "\n",
    "\n",
    "def get_qa_prompt(model_id:str, system_prompt:str, question: str, context: str, image: Image=None) -> str:\n",
    "    return  f\"[INST]{'<image>' if image else ' '}\\n{system_prompt}\\n{context}\\n\\nQuestion:\\n{question}\\n\\n[/INST]\"\n",
    "\n",
    "\n",
    "def format_output(raw_output, processor: LlavaNextProcessor, prompt: str) -> str:\n",
    "    out = processor.decode(raw_output[0], skip_special_tokens=True)\n",
    "    out_prompt = prompt.replace(\"<image>\", \" \").strip()\n",
    "    formatted_output = out.replace(out_prompt, \"\").strip()\n",
    "    return formatted_output\n",
    "\n",
    "\n",
    "def get_prompt(task: str, model_id: str, system_prompt: str, text: str, image: Image, question: str) -> str:\n",
    "    prompt = get_qa_prompt(model_id, system_prompt, question, text, image)\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def llava_call(prompt: str, model: LlavaNextForConditionalGeneration, processor: LlavaNextProcessor, device: str, image: Image=None) -> str:\n",
    "    inputs = processor(prompt, image, return_tensors=\"pt\").to(device)\n",
    "    raw_output = model.generate(**inputs, max_new_tokens=300)\n",
    "    formatted_output = format_output(raw_output, processor, prompt)\n",
    "    return formatted_output\n",
    "\n",
    "\n",
    "def load_llava_model(model_id: str) -> Tuple[LlavaNextForConditionalGeneration, LlavaNextProcessor]:\n",
    "    processor = LlavaNextProcessor.from_pretrained(model_id)\n",
    "    model = LlavaNextForConditionalGeneration.from_pretrained(model_id, quantization_config=quantization_config, device_map=\"auto\", cache_dir=root_path + \"/models\")\n",
    "    #model = LlavaNextForConditionalGeneration.from_pretrained(model_id, device_map=\"auto\")\n",
    "    return model, processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A95OjdWEbkpd"
   },
   "outputs": [],
   "source": [
    "from prompts import QA_PROMPT_SYSTEM, QA_PROMPT_USER\n",
    "\n",
    "def run_pileline_llava(question, text_vectorstore, img_vectorstore, model, processor, device=\"cuda\"):\n",
    "    text_content = text_vectorstore.similarity_search(question, k=4)\n",
    "    context = \"\\n\\n\".join([t.page_content for t in text_content])\n",
    "    image_content = img_vectorstore.similarity_search(question, k=1)\n",
    "\n",
    "    if len(image_content) > 0:\n",
    "      img_path = image_content[0].metadata[\"image_path\"]\n",
    "      image = Image.open(img_path)\n",
    "      img_prompt = get_qa_prompt(\"llava-hf/llava-v1.6-mistral-7b-hf\", QA_PROMPT_SYSTEM, question, context, image)\n",
    "      return llava_call(img_prompt, model, processor, device, image)\n",
    "\n",
    "    no_img_prompt = get_qa_prompt(\"llava-hf/llava-v1.6-mistral-7b-hf\", QA_PROMPT_SYSTEM, question, context)\n",
    "    return llava_call(no_img_prompt, model, processor, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0opZmJEAZ9CK"
   },
   "outputs": [],
   "source": [
    "question = \"Как выделить прямоугольную область на изображении в Adobe Photoshop?\"\n",
    "model, processor = load_llava_model(\"llava-hf/llava-v1.6-mistral-7b-hf\")\n",
    "model = model.eval()\n",
    "\n",
    "response = run_pileline_llava(question, text_vectorstore, img_vectorstore, model, processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2DRZ2gtjtX_"
   },
   "source": [
    "# Оценка ответа (DeepSeek-R1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "def init_deepseek():\n",
    "    return OllamaLLM(model=\"deepseek-r1:1.5b\", base_url=\"http://localhost:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from prompts import ANSWER_CORRECTNESS_SYSTEM, ANSWER_CORRECTNESS_USER\n",
    "\n",
    "answer_correctness = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", ANSWER_CORRECTNESS_SYSTEM),\n",
    "        (\"human\", ANSWER_CORRECTNESS_USER)\n",
    "    ]\n",
    ")\n",
    "llm = init_deepseek()\n",
    "\n",
    "answer_correctness_chain = answer_correctness | llm\n",
    "response = answer_correctness_chain.invoke(\"question\": question, \"reference_answer\": reference_answer, \"generated_answer\": generated_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from prompts import ANSWER_RELEVANCE_SYSTEM, ANSWER_RELEVANCE_USER\n",
    "\n",
    "answer_relevance = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", ANSWER_RELEVANCE_SYSTEM),\n",
    "        (\"human\", ANSWER_RELEVANCE_USER)\n",
    "    ]\n",
    ")\n",
    "llm = init_deepseek()\n",
    "\n",
    "answer_relevance_chain = answer_relevance | llm\n",
    "generated_answer = \"\"\"Чтобы выделить прямоугольную область в Photoshop, используйте инструмент \"Прямоугольная область\" (Rectangular Marquee Tool) на панели инструментов\"\"\"\n",
    "response = answer_relevance_chain.invoke(\"query\": question, \"text\": generated_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from prompts import CONTEXT_RELEVANCE_TEXT_SYSTEM, CONTEXT_RELEVANCE_TEXT_USER\n",
    "\n",
    "context_relevance_text = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", CONTEXT_RELEVANCE_TEXT_SYSTEM),\n",
    "        (\"human\", CONTEXT_RELEVANCE_TEXT_USER)\n",
    "    ]\n",
    ")\n",
    "llm = init_deepseek()\n",
    "\n",
    "\n",
    "context = \"\"\"Чтобы выделить прямоугольную область в Photoshop, используйте инструмент \"Прямоугольная область\" (Rectangular Marquee Tool) на панели инструментов\"\"\"\n",
    "context_relevance_text_chain = context_relevance_text | llm\n",
    "response = context_relevance_text_chain.invoke(\"query\": question, \"context\": context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from prompts import CONTEXT_RELEVANCE_IMAGE_SYSTEM, CONTEXT_RELEVANCE_IMAGE_USER\n",
    "\n",
    "context_relevance_image = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", CONTEXT_RELEVANCE_IMAGE_SYSTEM),\n",
    "        (\"human\", CONTEXT_RELEVANCE_IMAGE_USER)\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = init_deepseek()\n",
    "\n",
    "context_relevance_image_chain = context_relevance_image | llm\n",
    "response = context_relevance_image_chain.invoke(\"query\": question)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
