{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Мультимодальный RAG на описаниях изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#root_path = \"/content/drive/MyDrive/Diploma-mag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -q -U langchain langchain-gigachat open-clip-torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "skzuHQb6FYjX"
   },
   "outputs": [],
   "source": [
    "from langchain_gigachat import Gigachat\n",
    "from langchain_gigachat.embeddings import GigaChatEmbeddings\n",
    "\n",
    "def init_gigachat():\n",
    "    return Gigachat(credentials=\"ключ_авторизации\", model=\"GigaChat-Max\", verify_ssl_certs=False, temperature=1e-15, timeout=100)\n",
    "\n",
    "\n",
    "def init_gigachat_embeddings():\n",
    "    return GigaChatEmbeddings(credentials=\"ключ_авторизации\", scope-\"GIGACHAT_API_PER\", verify_ssl_certs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v8DRd6SsODol"
   },
   "outputs": [],
   "source": [
    "from langchain.storage import InMemoryStore\n",
    "\n",
    "llm = init_gigachat()\n",
    "embeddings = init_gigachat_embeddings()\n",
    "\n",
    "id_key = \"doc_id\"\n",
    "doc_ids = []\n",
    "\n",
    "docstore_dir = \"./data/multimodal_rag_with_summaries/doc_store\"\n",
    "vectorstore_dir = \"./data/multimodal_rag_with_summaries/vectorstore\"\n",
    "\n",
    "docstore = InMemoryStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GpykBePKOHAH"
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers import MultiVectorRetriever\n",
    "from langchain_chroma import Chroma\n",
    "from chromadb.config import Settings\n",
    "\n",
    "\n",
    "text_vectorstore = Chroma(\n",
    "    persist_directory=vectorstore_dir,\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"mm_rag_text_gigaembeddings\",\n",
    "    client_settings=Settings(anonymized_telemetry=False)\n",
    ")\n",
    "\n",
    "retriever = MultiVectorRetriever(\n",
    "        vectorstore=text_vectorstore,\n",
    "        docstore=docstore,\n",
    "        id_key=id_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ATq8HE5vOKUH"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"./extracted_data/extracted_texts.json\", \"r\") as f:\n",
    "    documents = json.load(f)\n",
    "\n",
    "with open(\"./extracted_data/image_summary.json\", \"r\") as f:\n",
    "    summaries = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56fW2M2IOMZ3"
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "documents_content = []\n",
    "documents_page = []\n",
    "\n",
    "for d in documents:\n",
    "    documents_content.append(d[\"text\"])\n",
    "    documents_page.append(d[\"metadata\"][\"page_number\"])\n",
    "\n",
    "\n",
    "doc_ids = [str(uuid.uuid4()) for _ in documents_content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M6ndpJsGOO34"
   },
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "\n",
    "prepared_text = []\n",
    "for i, document_content in enumerate(documents_content):\n",
    "    chunks = text_splitter.split_text(document_content)\n",
    "    prepared_text += [Document(\n",
    "        page_content=chunk,\n",
    "        metadata={\n",
    "            \"page_number\": documents_page[i],\n",
    "            \"doc_id\": doc_ids[i]\n",
    "        })\n",
    "    for j, chunk in enumerate(chunks)]\n",
    "\n",
    "all_chunks = [text.page_content for text in prepared_text]\n",
    "\n",
    "text_vectorstore.add_documents(prepared_text)\n",
    "retriever.docstore.mset(list(zip(doc_ids, documents_content)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQMWWgW7OTaB"
   },
   "outputs": [],
   "source": [
    "summaries_content = []\n",
    "summaries_page = []\n",
    "summaries_source = []\n",
    "\n",
    "for s in summaries:\n",
    "    summaries_content.append(s[\"image_summary\"])\n",
    "    summaries_page.append(s[\"page_number\"])\n",
    "    summaries_source.append(s[\"source\"])\n",
    "\n",
    "summaries_ids = [str(uuid.uuid4()) for _ in summaries_content]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "\n",
    "prepared_text = []\n",
    "for i, summary_content in enumerate(summaries_content):\n",
    "    chunks = text_splitter.split_text(summary_content)\n",
    "    prepared_text += [Document(\n",
    "        page_content=chunk,\n",
    "        metadata={\n",
    "            \"page_number\": summaries_content[i],\n",
    "            \"doc_id\": summaries_ids[i],\n",
    "            \"source\": summaries_source[i]\n",
    "        })\n",
    "    for j, chunk in enumerate(chunks)]\n",
    "\n",
    "retriever.vectorstore.add_documents(prepared_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пайплайн GigaChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from prompts import QA_PROMPT_SYSTEM, QA_PROMPT_USER\n",
    "\n",
    "def run_pipeline_gigachat(question, text_vectorstore, img_vectorstore, llm):\n",
    "    response = retriever.invoke(question)\n",
    "    images = []\n",
    "    texts = []\n",
    "    \n",
    "    for r in response:\n",
    "        if r.metadata.get(\"source\", None) is not None:\n",
    "            images.append(r)\n",
    "        else:\n",
    "            texts.append(r)\n",
    "\n",
    "\n",
    "    context = \"\\n\\n\".join([t.page_content for t in texts])\n",
    "    \n",
    "    file = None\n",
    "    if len(images) > 0:\n",
    "        img_path = images[0].metadata[\"source\"]\n",
    "        file = llm.upload_file(open(img_path, \"rb\"))\n",
    "\n",
    "    text_content = QA_PROMPT_USER.format(context=context, question=question)\n",
    "\n",
    "    if file is not None:\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", QA_PROMPT_SYSTEM),\n",
    "                HumanMessage(content=text_content, additional_kwargs={\"attachments\": [file.id_]})\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", QA_PROMPT_SYSTEM),\n",
    "                HumanMessage(content=text_content)\n",
    "            ]\n",
    "        )\n",
    "    chain = prompt | llm\n",
    "\n",
    "    return  chain.invoke({}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Как выделить прямоугольную область на изображении в Adobe Photoshop?\"\n",
    "run_pipeline_gigachat(question, text_vectorstore, img_vectorstore, llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пайплайн LLaVa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q -U transformers bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig, LlavaNextProcessor, LlavaNextForConditionalGeneration\n",
    "from PIL import Image\n",
    "import io\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    low_cpu_mem_usage=True,\n",
    "    use_flash_attention_2=True\n",
    ")\n",
    "\n",
    "\n",
    "def get_qa_prompt(model_id:str, system_prompt:str, question: str, context: str, image: Image=None) -> str:\n",
    "    return  f\"[INST]{'<image>' if image else ' '}\\n{system_prompt}\\n{context}\\n\\nQuestion:\\n{question}\\n\\n[/INST]\"\n",
    "\n",
    "\n",
    "def format_output(raw_output, processor: LlavaNextProcessor, prompt: str) -> str:\n",
    "    out = processor.decode(raw_output[0], skip_special_tokens=True)\n",
    "    out_prompt = prompt.replace(\"<image>\", \" \").strip()\n",
    "    formatted_output = out.replace(out_prompt, \"\").strip()\n",
    "    return formatted_output\n",
    "\n",
    "\n",
    "def get_prompt(task: str, model_id: str, system_prompt: str, text: str, image: Image, question: str) -> str:\n",
    "    prompt = get_qa_prompt(model_id, system_prompt, question, text, image)\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def llava_call(prompt: str, model: LlavaNextForConditionalGeneration, processor: LlavaNextProcessor, device: str, image: Image=None) -> str:\n",
    "    inputs = processor(prompt, image, return_tensors=\"pt\").to(device)\n",
    "    raw_output = model.generate(**inputs, max_new_tokens=300)\n",
    "    formatted_output = format_output(raw_output, processor, prompt)\n",
    "    return formatted_output\n",
    "\n",
    "\n",
    "def load_llava_model(model_id: str) -> Tuple[LlavaNextForConditionalGeneration, LlavaNextProcessor]:\n",
    "    processor = LlavaNextProcessor.from_pretrained(model_id)\n",
    "    model = LlavaNextForConditionalGeneration.from_pretrained(model_id, quantization_config=quantization_config, device_map=\"auto\", cache_dir=root_path + \"/models\")\n",
    "    #model = LlavaNextForConditionalGeneration.from_pretrained(model_id, device_map=\"auto\")\n",
    "    return model, processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import QA_PROMPT_SYSTEM, QA_PROMPT_USER\n",
    "\n",
    "def run_pileline_llava(question, text_vectorstore, img_vectorstore, model, processor, device=\"cuda\"):\n",
    "    response = retriever.invoke(question)\n",
    "    images = []\n",
    "    texts = []\n",
    "    \n",
    "    for r in response:\n",
    "        if r.metadata.get(\"source\", None) is not None:\n",
    "            images.append(r)\n",
    "        else:\n",
    "            texts.append(r)\n",
    "\n",
    "    context = \"\\n\\n\".join([t.page_content for t in text_content])\n",
    "\n",
    "    if len(images) > 0:\n",
    "      img_path = images[0].metadata[\"source\"]\n",
    "      image = Image.open(img_path)\n",
    "      img_prompt = get_qa_prompt(\"llava-hf/llava-v1.6-mistral-7b-hf\", QA_PROMPT_SYSTEM, question, context, image)\n",
    "      return llava_call(img_prompt, model, processor, device, image)\n",
    "\n",
    "    no_img_prompt = get_qa_prompt(\"llava-hf/llava-v1.6-mistral-7b-hf\", QA_PROMPT_SYSTEM, question, context)\n",
    "    return llava_call(no_img_prompt, model, processor, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Как выделить прямоугольную область на изображении в Adobe Photoshop?\"\n",
    "model, processor = load_llava_model(\"llava-hf/llava-v1.6-mistral-7b-hf\")\n",
    "model = model.eval()\n",
    "\n",
    "response = run_pileline_llava(question, text_vectorstore, img_vectorstore, model, processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка ответа (DeepSeek-R1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_gigachat import Gigachat\n",
    "def init_deepseek():\n",
    "    return Gigachat(credentials=\"ваш_ключ_авторизации\", model=\"DeepSeek-R1\", verify_ssl_certs=False, temperature=1e-15, timeout=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from prompts import ANSWER_CORRECTNESS_SYSTEM, ANSWER_CORRECTNESS_USER\n",
    "\n",
    "answer_correctness = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", ANSWER_CORRECTNESS_SYSTEM),\n",
    "        (\"human\", ANSWER_CORRECTNESS_USER)\n",
    "    ]\n",
    ")\n",
    "llm = init_deepseek()\n",
    "\n",
    "answer_correctness_chain = answer_correctness | llm\n",
    "response = answer_correctness_chain.invoke(\"question\": question, \"reference_answer\": reference_answer, \"generated_answer\": generated_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from prompts import ANSWER_RELEVANCE_SYSTEM, ANSWER_RELEVANCE_USER\n",
    "\n",
    "answer_relevance = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", ANSWER_RELEVANCE_SYSTEM),\n",
    "        (\"human\", ANSWER_RELEVANCE_USER)\n",
    "    ]\n",
    ")\n",
    "llm = init_deepseek()\n",
    "\n",
    "answer_relevance_chain = answer_relevance | llm\n",
    "generated_answer = \"\"\"Чтобы выделить прямоугольную область в Photoshop, используйте инструмент \"Прямоугольная область\" (Rectangular Marquee Tool) на панели инструментов\"\"\"\n",
    "response = answer_relevance_chain.invoke(\"query\": question, \"text\": generated_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from prompts import CONTEXT_RELEVANCE_TEXT_SYSTEM, CONTEXT_RELEVANCE_TEXT_USER\n",
    "\n",
    "context_relevance_text = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", CONTEXT_RELEVANCE_TEXT_SYSTEM),\n",
    "        (\"human\", CONTEXT_RELEVANCE_TEXT_USER)\n",
    "    ]\n",
    ")\n",
    "llm = init_deepseek()\n",
    "\n",
    "\n",
    "context = \"\"\"Чтобы выделить прямоугольную область в Photoshop, используйте инструмент \"Прямоугольная область\" (Rectangular Marquee Tool) на панели инструментов\"\"\"\n",
    "context_relevance_text_chain = context_relevance_text | llm\n",
    "response = context_relevance_text_chain.invoke(\"query\": question, \"context\": context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from prompts import CONTEXT_RELEVANCE_IMAGE_SYSTEM, CONTEXT_RELEVANCE_IMAGE_USER\n",
    "\n",
    "context_relevance_image = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", CONTEXT_RELEVANCE_IMAGE_SYSTEM),\n",
    "        (\"human\", CONTEXT_RELEVANCE_IMAGE_USER)\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = init_deepseek()\n",
    "\n",
    "context_relevance_image_chain = context_relevance_image | llm\n",
    "response = context_relevance_image_chain.invoke(\"query\": question)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
